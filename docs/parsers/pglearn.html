<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.5">
<title>ml4opf.parsers.pglearn API documentation</title>
<meta name="description" content="Parser for the PGLearn datasets">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ml4opf.parsers.pglearn</code></h1>
</header>
<section id="section-intro">
<p>Parser for the PGLearn datasets</p>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ml4opf.parsers.pglearn.MaybeGunzipH5File"><code class="flex name class">
<span>class <span class="ident">MaybeGunzipH5File</span></span>
<span>(</span><span>name: str, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L317-L336" class="git-link">Browse git</a></div>
<div class="desc"><p>Represents an HDF5 file.</p>
<p>Create a new file object.</p>
<p>See the h5py user guide for a detailed explanation of the options.</p>
<p>name
Name of the file on disk, or file-like object.
Note: for files
created with the 'core' driver, HDF5 still requires this be
non-empty.
mode
r
Readonly, file must exist (default)
r+
Read/write, file must exist
w
Create file, truncate if exists
w- or x
Create file, fail if exists
a
Read/write if exists, create otherwise
driver
Name of the driver to use.
Legal values are None (default,
recommended), 'core', 'sec2', 'direct', 'stdio', 'mpio', 'ros3'.
libver
Library version bounds.
Supported values: 'earliest', 'v108',
'v110', 'v112'
and 'latest'.
userblock_size
Desired size of user block.
Only allowed when creating a new
file (mode w, w- or x).
swmr
Open the file in SWMR read mode. Only used when mode = 'r'.
rdcc_nbytes
Total size of the dataset chunk cache in bytes. The default size
is 1024**2 (1 MiB) per dataset. Applies to all datasets unless individually changed.
rdcc_w0
The chunk preemption policy for all datasets.
This must be
between 0 and 1 inclusive and indicates the weighting according to
which chunks which have been fully read or written are penalized
when determining which chunks to flush from cache.
A value of 0
means fully read or written chunks are treated no differently than
other chunks (the preemption is strictly LRU) while a value of 1
means fully read or written chunks are always preempted before
other chunks.
If your application only reads or writes data once,
this can be safely set to 1.
Otherwise, this should be set lower
depending on how often you re-read or re-write the same data.
The
default value is 0.75. Applies to all datasets unless individually changed.
rdcc_nslots
The number of chunk slots in the raw data chunk cache for this
file. Increasing this value reduces the number of cache collisions,
but slightly increases the memory used. Due to the hashing
strategy, this value should ideally be a prime number. As a rule of
thumb, this value should be at least 10 times the number of chunks
that can fit in rdcc_nbytes bytes. For maximum performance, this
value should be set approximately 100 times that number of
chunks. The default value is 521. Applies to all datasets unless individually changed.
track_order
Track dataset/group/attribute creation order under root group
if True. If None use global default h5.get_config().track_order.
fs_strategy
The file space handling strategy to be used.
Only allowed when
creating a new file (mode w, w- or x).
Defined as:
"fsm"
FSM, Aggregators, VFD
"page"
Paged FSM, VFD
"aggregate"
Aggregators, VFD
"none"
VFD
If None use HDF5 defaults.
fs_page_size
File space page size in bytes. Only used when fs_strategy="page". If
None use the HDF5 default (4096 bytes).
fs_persist
A boolean value to indicate whether free space should be persistent
or not.
Only allowed when creating a new file.
The default value
is False.
fs_threshold
The smallest free-space section size that the free space manager
will track.
Only allowed when creating a new file.
The default
value is 1.
page_buf_size
Page buffer size in bytes. Only allowed for HDF5 files created with
fs_strategy="page". Must be a power of two value and greater or
equal than the file space page size when creating the file. It is
not used by default.
min_meta_keep
Minimum percentage of metadata to keep in the page buffer before
allowing pages containing metadata to be evicted. Applicable only if
page_buf_size is set. Default value is zero.
min_raw_keep
Minimum percentage of raw data to keep in the page buffer before
allowing pages containing raw data to be evicted. Applicable only if
page_buf_size is set. Default value is zero.
locking
The file locking behavior. Defined as:</p>
<pre><code>- False (or "false") --  Disable file locking
- True (or "true")   --  Enable file locking
- "best-effort"      --  Enable file locking but ignore some errors
- None               --  Use HDF5 defaults

!!! warning "Warning"
    The HDF5_USE_FILE_LOCKING environment variable can override
    this parameter.


Only available with HDF5 &gt;= 1.12.1 or 1.10.x &gt;= 1.10.7.
</code></pre>
<p>alignment_threshold
Together with <code>alignment_interval</code>, this property ensures that
any file object greater than or equal in size to the alignment
threshold (in bytes) will be aligned on an address which is a
multiple of alignment interval.</p>
<p>alignment_interval
This property should be used in conjunction with
<code>alignment_threshold</code>. See the description above. For more
details, see
<a href="https://portal.hdfgroup.org/display/HDF5/H5P_SET_ALIGNMENT">https://portal.hdfgroup.org/display/HDF5/H5P_SET_ALIGNMENT</a></p>
<p>meta_block_size
Set the current minimum size, in bytes, of new metadata block allocations.
See <a href="https://portal.hdfgroup.org/display/HDF5/H5P_SET_META_BLOCK_SIZE">https://portal.hdfgroup.org/display/HDF5/H5P_SET_META_BLOCK_SIZE</a></p>
<p>Additional keywords
Passed on to the selected file driver.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>h5py._hl.files.File</li>
<li>h5py._hl.group.Group</li>
<li>h5py._hl.base.HLObject</li>
<li>h5py._hl.base.CommonStateObject</li>
<li>h5py._hl.base.MutableMappingHDF5</li>
<li>h5py._hl.base.MappingHDF5</li>
<li>collections.abc.MutableMapping</li>
<li>collections.abc.Mapping</li>
<li>collections.abc.Collection</li>
<li>collections.abc.Sized</li>
<li>collections.abc.Iterable</li>
<li>collections.abc.Container</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ml4opf.parsers.pglearn.MaybeGunzipH5File.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L333-L336" class="git-link">Browse git</a></div>
<div class="desc"><p>Close the file.
All open objects become invalid</p></div>
</dd>
</dl>
</dd>
<dt id="ml4opf.parsers.pglearn.PGLearnParser"><code class="flex name class">
<span>class <span class="ident">PGLearnParser</span></span>
<span>(</span><span>data_path: str | pathlib.Path)</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L22-L314" class="git-link">Browse git</a></div>
<div class="desc"><p>Parser for PGLearn dataset.</p>
<p>Initialize the parser by validating and setting the path.</p></div>
<h3>Class variables</h3>
<dl>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.padval"><code class="name">var <span class="ident">padval</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.convert_to_float32"><code class="name flex">
<span>def <span class="ident">convert_to_float32</span></span>(<span>dat: dict[str, torch.Tensor | numpy.ndarray | numpy.str_])</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L150-L156" class="git-link">Browse git</a></div>
<div class="desc"><p>Convert all float64 data to float32 in-place.</p></div>
</dd>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.make_tree"><code class="name flex">
<span>def <span class="ident">make_tree</span></span>(<span>dat: dict[str, torch.Tensor | numpy.ndarray | numpy.str_],<br>delimiter: str = '/')</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L158-L186" class="git-link">Browse git</a></div>
<div class="desc"><p>Convert a flat dictionary to a tree.
Note that the keys of <code>dat</code> must have a tree structure where data is only at the leaves.
Assumes keys are delimited by "/", i.e. "solution/primal/pg".</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dat</code></strong> :&ensp;<code>dict</code></dt>
<dd>Flat dictionary of data.</dd>
<dt><strong><code>delimiter</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Delimiter to use for splitting keys. Defaults to "/".</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Tree dictionary of data from <code>dat</code>.</dd>
</dl></div>
</dd>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.pad_to_dense"><code class="name flex">
<span>def <span class="ident">pad_to_dense</span></span>(<span>array, padval, dtype=builtins.int)</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L285-L314" class="git-link">Browse git</a></div>
<div class="desc"><p>from <a href="https://codereview.stackexchange.com/questions/222623/pad-a-ragged-multidimensional-array-to-rectangular-shape">https://codereview.stackexchange.com/questions/222623/pad-a-ragged-multidimensional-array-to-rectangular-shape</a></p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.open_json"><code class="name flex">
<span>def <span class="ident">open_json</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L192-L202" class="git-link">Browse git</a></div>
<div class="desc"><p>Open the JSON file, supporting gzip and bz2 compression based on the file suffix.</p></div>
</dd>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.parse_h5"><code class="name flex">
<span>def <span class="ident">parse_h5</span></span>(<span>self,<br>dataset_name: str,<br>split: str = 'train',<br>primal: bool = True,<br>dual: bool = False,<br>convert_to_float32: bool = True) ‑> dict[str, torch.Tensor | numpy.ndarray | numpy.str_] | tuple[dict[str, torch.Tensor | numpy.ndarray | numpy.str_], dict[str, torch.Tensor | numpy.ndarray | numpy.str_]]</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L52-L148" class="git-link">Browse git</a></div>
<div class="desc"><p>Parse the HDF5 file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the dataset. Typically the formulation ("ACOPF", "DCOPF", etc.).</dd>
<dt><strong><code>split</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The split to return. Defaults to "train".</dd>
<dt><strong><code>primal</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, parse the primal file. Defaults to True.</dd>
<dt><strong><code>dual</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, parse the dual file. Defaults to False.</dd>
<dt><strong><code>convert_to_float32</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, convert all float64 data to torch.float32. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Flattened dictionary of HDF5 data with PyTorch tensors for numerical data and NumPy arrays for string/object data.</dd>
</dl>
<p>If <code>make_test_set</code> is True, then this function will return a tuple of two dictionaries. The first dictionary is the
training set and the second dictionary is the test set. The test set is a random 10% sample of the training set.</p>
<p>This parser will return a single-level dictionary where the keys are in the form
of <code>solution/primal/pg</code> where <code>solution</code> is the group, <code>primal</code> is the subgroup,
and <code>pg</code> is the dataset from the HDF5 file. The values are PyTorch tensors. This
parser uses <code>h5py.File.visititems</code> to iterate over the HDF5 file quickly.</p></div>
</dd>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.parse_json"><code class="name flex">
<span>def <span class="ident">parse_json</span></span>(<span>self, model_type: str | Sequence[str] = None)</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L204-L276" class="git-link">Browse git</a></div>
<div class="desc"><p>Parse the JSON file from PGLearn.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_type</code></strong> :&ensp;<code>Union[str, Sequence[str]]</code></dt>
<dd>The reference solutions to save. Default: [] (no reference solutions saved.)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Dictionary containing the parsed data.</dd>
</dl>
<p>In the JSON file, the data is stored by each individual component.
So to get generator 1's upper bound on active generation, you'd look at:
raw_json['data']['gen']['1']['pmax'] and get a float.</p>
<p>In the parsed version, we aggregate each of the components attributes into torch.Tensor arrays.
So to get generator 1's upper bound on active generation, you'd look at:
dat['gen']['pmax'][0] and get a float.
Note that the index is 0-based and an integer, not 1-based and a string.</p>
<p>To access the reference solution, pass a model_type (or multiple) and then access dat["ref_solutions"][model_type].</p></div>
</dd>
<dt id="ml4opf.parsers.pglearn.PGLearnParser.validate_path"><code class="name flex">
<span>def <span class="ident">validate_path</span></span>(<span>self, path: str | pathlib.Path) ‑> pathlib.Path</span>
</code></dt>
<dd>
<div class="git-link-div"><a href="https://github.com/AI4OPT/ML4OPF/blob/8f8e6125352203d112bba4c89092347fd7629c56/ml4opf/parsers/pglearn.py#L32-L46" class="git-link">Browse git</a></div>
<div class="desc"><p>Validate the path to the HDF5 file.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ml4opf.parsers" href="index.html">ml4opf.parsers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ml4opf.parsers.pglearn.MaybeGunzipH5File" href="#ml4opf.parsers.pglearn.MaybeGunzipH5File">MaybeGunzipH5File</a></code></h4>
<ul class="">
<li><code><a title="ml4opf.parsers.pglearn.MaybeGunzipH5File.close" href="#ml4opf.parsers.pglearn.MaybeGunzipH5File.close">close</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ml4opf.parsers.pglearn.PGLearnParser" href="#ml4opf.parsers.pglearn.PGLearnParser">PGLearnParser</a></code></h4>
<ul class="two-column">
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.convert_to_float32" href="#ml4opf.parsers.pglearn.PGLearnParser.convert_to_float32">convert_to_float32</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.make_tree" href="#ml4opf.parsers.pglearn.PGLearnParser.make_tree">make_tree</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.open_json" href="#ml4opf.parsers.pglearn.PGLearnParser.open_json">open_json</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.pad_to_dense" href="#ml4opf.parsers.pglearn.PGLearnParser.pad_to_dense">pad_to_dense</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.padval" href="#ml4opf.parsers.pglearn.PGLearnParser.padval">padval</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.parse_h5" href="#ml4opf.parsers.pglearn.PGLearnParser.parse_h5">parse_h5</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.parse_json" href="#ml4opf.parsers.pglearn.PGLearnParser.parse_json">parse_json</a></code></li>
<li><code><a title="ml4opf.parsers.pglearn.PGLearnParser.validate_path" href="#ml4opf.parsers.pglearn.PGLearnParser.validate_path">validate_path</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.5</a>.</p>
</footer>
</body>
</html>
